# Overview
This ASL Detector is a cutting-edge AI-powered application that uses computer vision and deep learning to recognize and classify American Sign Language (ASL) characters in real-time. This application utilizes the device's camera to capture hand landmarks and coordinates, which are then processed by a deep learning model to identify the corresponding ASL character.

# Table of Contents
1. Introduction
2. Features
3. Installation
Usage
Model Training
Contributing
License
Acknowledgements

# Features
* **Real-time ASL detection using the device's camera.**
* **Accurate classification of ASL characters using a deep learning model.**
* **Hand landmark tracking for precise gesture recognition.**
* **Support for a wide range of ASL characters and phrases.**
* **High accuracy and robustness in varying lighting conditions.**

# Requirements:
* OpenCV
* MediaPipe
* Pillow
* NumPy
* Pandas
* Seaborn
* Scikit-learn
* Matplotlib
* Tensorflow
> Note: If you face an error during training from the line converting to the tflite model, use TensorFlow v2.16.1.

# Installation:
1. Clone the Repository:
```
git clone https://github.com/AkramOM606/American-Sign-Language-Detection.git
cd American-Sign-Language-Detection
```
3. Install Dependencies:
```
pip install -r requirements.txt
```
4. Run the Application:
```
python main.py
```
# Directory (Project Layout)

# Training

# Usage ?

# Contributing
We welcome contributions to enhance this project! Feel free to:

1. Fork the repository.
2. Create a new branch for your improvements.
3. Make your changes and commit them.
4. Open a pull request to propose your contributions.
5. We'll review your pull request and provide feedback promptly.

# License
This project is licensed under the MIT License: https://opensource.org/licenses/MIT (see LICENSE.md for details).
